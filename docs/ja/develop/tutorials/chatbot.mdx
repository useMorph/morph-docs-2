---
title: 'チャットアプリを作成する'
icon: "message-dots"
---

Morphでは、LLMのAPIを活用したチャットアプリを簡単に作成して、チームに共有することができます。

このチュートリアルでは、MorphのLLMコンポーネントとOpenAIのAPIを使用して、チャットアプリを作成します。

## 事前準備

OpenAIのAPIキーを事前にOpenAIのダッシュボードから取得して、`.env`ファイルに保存してください。

```shell .env
OPENAI_API_KEY=your_api_key
```

<Warning>
クラウド環境をお使いの場合は、"Data"タブから環境変数として設定してください。
</Warning>


## 最終的な成果物

![chatbot](/assets/images/docs/tutorial/llm_chat_app.png)

## チュートリアル

`<LLM />`コンポーネントを使用して、LLMのAPIを活用したチャットアプリを作成します。
Python関数でLLMを用いたチャットアプリのロジックを実装し、`create_chunk`関数を使用して、チャットのログをストリームで返することで、自動的に`<LLM />`がストリーミングの結果を表示します。

<Tabs>
    <Tab title="1. Python">
OpenAIのSDKを使用して、ユーザーからの質問に回答するロジックを実装します。
`<LLM />`コンポーネントの`postData`属性に指定された関数は`prompt`と`thread_id`を引数として受け取ります。
- prompt: ユーザーから入力されたプロンプト
- thread_id: チャットスレッドのID。新しいスレッドが開かれると新しいIDが発行されます。

```python
import os
import morph
from morph import MorphGlobalContext
from morph_lib.stream import create_chunk
from openai import OpenAI

@morph.func
def llm_chat_app(context: MorphGlobalContext):
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    prompt = context.vars["prompt"]
    # thread_id can be used to identify the chat thread
    thread_id = context.vars["thread_id"]

    # chat
    messages = [{"role": "user", "content": prompt}]
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        stream=True,
    )

    for chunk in response:
        yield create_chunk(chunk.choices[0].delta.content)

```
    </Tab>
    <Tab title="2. MDX(pages)">
`<LLM />`コンポーネントの`postData`属性にPython関数を指定します。

```typescript
export const title = "LLM Chat App"

# LLM Chat App

<LLM postData="llm_chat_app" />

```
    </Tab>
</Tabs>
