---
title: 'Job Scheduling'
---

This section describes a mechanism for scheduling and executing data pipelines created in SQL or Python.

Functions such as `load_data` in SQL and `@morph.load_data()` in Python allow multiple processes to be built as a pipeline.
Scheduled execution of this pipeline can automate recurring tasks such as daily sales totals.

By opening the Jobs tab, you can check the currently set jobs and register new jobs.

<iframe
    src="https://www.loom.com/embed/4b608b640dc340ca8b730b600a6d8273?sid=9fe2ca61-bff5-4804-b556-738ebc12e83e"
    controls
    className="w-full aspect-video"
></iframe>

You can check the logs and execution results when the job is executed by opening the detailed page.

<img
    src="/assets/images/docs/workspace-job-schedule-detail.png"
    alt="Job Schedule Detail"
/>

## Job scheduling settings

Job scheduling should be configured for the last function in the pipeline.
The `load_data` function also executes the function to be loaded at runtime, so any data pipeline can be executed periodically by specifying the last function in the data pipeline.

The execution date and time can be set flexibly, such as ‘every day’ or ‘only on weekdays’. The execution time can also be set in 15-minute increments.

<iframe
    src="https://www.loom.com/embed/4177425642e941d0841dd31e152da289?sid=b3523927-36dd-4612-a705-a9866a8fb0f1"
    controls
    className="w-full aspect-video"
></iframe>

